{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5efb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/raw/olist_orders_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d978b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_status: 8 unique values\n",
      "order_status\n",
      "delivered      96478\n",
      "shipped         1107\n",
      "canceled         625\n",
      "unavailable      609\n",
      "invoiced         314\n",
      "processing       301\n",
      "created            5\n",
      "approved           2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"order_status: {df['order_status'].nunique()} unique values\")\n",
    "print(df['order_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a33e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness (%) by order_status:\n",
      "              order_purchase_timestamp  order_approved_at  \\\n",
      "order_status                                                \n",
      "approved                           0.0           0.000000   \n",
      "canceled                           0.0          22.560000   \n",
      "created                            0.0         100.000000   \n",
      "delivered                          0.0           0.014511   \n",
      "invoiced                           0.0           0.000000   \n",
      "processing                         0.0           0.000000   \n",
      "shipped                            0.0           0.000000   \n",
      "unavailable                        0.0           0.000000   \n",
      "\n",
      "              order_delivered_carrier_date  order_delivered_customer_date  \\\n",
      "order_status                                                                \n",
      "approved                        100.000000                     100.000000   \n",
      "canceled                         88.000000                      99.040000   \n",
      "created                         100.000000                     100.000000   \n",
      "delivered                         0.002073                       0.008292   \n",
      "invoiced                        100.000000                     100.000000   \n",
      "processing                      100.000000                     100.000000   \n",
      "shipped                           0.000000                     100.000000   \n",
      "unavailable                     100.000000                     100.000000   \n",
      "\n",
      "              order_estimated_delivery_date  \n",
      "order_status                                 \n",
      "approved                                0.0  \n",
      "canceled                                0.0  \n",
      "created                                 0.0  \n",
      "delivered                               0.0  \n",
      "invoiced                                0.0  \n",
      "processing                              0.0  \n",
      "shipped                                 0.0  \n",
      "unavailable                             0.0  \n"
     ]
    }
   ],
   "source": [
    "date_cols = [c for c in df.columns if ('date' in c.lower() or 'timestamp' in c.lower() or c.endswith('_at'))]\n",
    "# ensure they're datetimes (bad parses become NaT)\n",
    "for c in date_cols:\n",
    "    df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "\n",
    "miss_pct = df.groupby('order_status')[date_cols].apply(lambda x: x.isna().mean() * 100)\n",
    "print(\"Missingness (%) by order_status:\")\n",
    "print(miss_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a08ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "order_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "customer_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "order_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "order_purchase_timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "order_approved_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "order_delivered_carrier_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "order_delivered_customer_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "order_estimated_delivery_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "0b8c857c-c90f-4110-9d11-7d2c794d5b88",
       "rows": [
        [
         "3002",
         "2d1e2d5bf4dc7227b3bfebb81328c15f",
         "ec05a6d8558c6455f0cbbd8a420ad34f",
         "delivered",
         "2017-11-28 17:44:07",
         "2017-11-28 17:56:40",
         "2017-11-30 18:12:23",
         null,
         "2017-12-18 00:00:00"
        ],
        [
         "20618",
         "f5dd62b788049ad9fc0526e3ad11a097",
         "5e89028e024b381dc84a13a3570decb4",
         "delivered",
         "2018-06-20 06:58:43",
         "2018-06-20 07:19:05",
         "2018-06-25 08:05:00",
         null,
         "2018-07-16 00:00:00"
        ],
        [
         "43834",
         "2ebdfc4f15f23b91474edf87475f108e",
         "29f0540231702fda0cfdee0a310f11aa",
         "delivered",
         "2018-07-01 17:05:11",
         "2018-07-01 17:15:12",
         "2018-07-03 13:57:00",
         null,
         "2018-07-30 00:00:00"
        ],
        [
         "79263",
         "e69f75a717d64fc5ecdfae42b2e8e086",
         "cfda40ca8dd0a5d486a9635b611b398a",
         "delivered",
         "2018-07-01 22:05:55",
         "2018-07-01 22:15:14",
         "2018-07-03 13:57:00",
         null,
         "2018-07-30 00:00:00"
        ],
        [
         "82868",
         "0d3268bad9b086af767785e3f0fc0133",
         "4f1d63d35fb7c8999853b2699f5c7649",
         "delivered",
         "2018-07-01 21:14:02",
         "2018-07-01 21:29:54",
         "2018-07-03 09:28:00",
         null,
         "2018-07-24 00:00:00"
        ],
        [
         "92643",
         "2d858f451373b04fb5c984a1cc2defaf",
         "e08caf668d499a6d643dafd7c5cc498a",
         "delivered",
         "2017-05-25 23:22:43",
         "2017-05-25 23:30:16",
         null,
         null,
         "2017-06-23 00:00:00"
        ],
        [
         "97647",
         "ab7c89dc1bf4a1ead9d6ec1ec8968a84",
         "dd1b84a7286eb4524d52af4256c0ba24",
         "delivered",
         "2018-06-08 12:09:39",
         "2018-06-08 12:36:39",
         "2018-06-12 14:10:00",
         null,
         "2018-06-26 00:00:00"
        ],
        [
         "98038",
         "20edc82cf5400ce95e1afacc25798b31",
         "28c37425f1127d887d7337f284080a0f",
         "delivered",
         "2018-06-27 16:09:12",
         "2018-06-27 16:29:30",
         "2018-07-03 19:26:00",
         null,
         "2018-07-19 00:00:00"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>2d1e2d5bf4dc7227b3bfebb81328c15f</td>\n",
       "      <td>ec05a6d8558c6455f0cbbd8a420ad34f</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-28 17:44:07</td>\n",
       "      <td>2017-11-28 17:56:40</td>\n",
       "      <td>2017-11-30 18:12:23</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20618</th>\n",
       "      <td>f5dd62b788049ad9fc0526e3ad11a097</td>\n",
       "      <td>5e89028e024b381dc84a13a3570decb4</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-06-20 06:58:43</td>\n",
       "      <td>2018-06-20 07:19:05</td>\n",
       "      <td>2018-06-25 08:05:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43834</th>\n",
       "      <td>2ebdfc4f15f23b91474edf87475f108e</td>\n",
       "      <td>29f0540231702fda0cfdee0a310f11aa</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-01 17:05:11</td>\n",
       "      <td>2018-07-01 17:15:12</td>\n",
       "      <td>2018-07-03 13:57:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79263</th>\n",
       "      <td>e69f75a717d64fc5ecdfae42b2e8e086</td>\n",
       "      <td>cfda40ca8dd0a5d486a9635b611b398a</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-01 22:05:55</td>\n",
       "      <td>2018-07-01 22:15:14</td>\n",
       "      <td>2018-07-03 13:57:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82868</th>\n",
       "      <td>0d3268bad9b086af767785e3f0fc0133</td>\n",
       "      <td>4f1d63d35fb7c8999853b2699f5c7649</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-01 21:14:02</td>\n",
       "      <td>2018-07-01 21:29:54</td>\n",
       "      <td>2018-07-03 09:28:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92643</th>\n",
       "      <td>2d858f451373b04fb5c984a1cc2defaf</td>\n",
       "      <td>e08caf668d499a6d643dafd7c5cc498a</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-05-25 23:22:43</td>\n",
       "      <td>2017-05-25 23:30:16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97647</th>\n",
       "      <td>ab7c89dc1bf4a1ead9d6ec1ec8968a84</td>\n",
       "      <td>dd1b84a7286eb4524d52af4256c0ba24</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-06-08 12:09:39</td>\n",
       "      <td>2018-06-08 12:36:39</td>\n",
       "      <td>2018-06-12 14:10:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98038</th>\n",
       "      <td>20edc82cf5400ce95e1afacc25798b31</td>\n",
       "      <td>28c37425f1127d887d7337f284080a0f</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-06-27 16:09:12</td>\n",
       "      <td>2018-06-27 16:29:30</td>\n",
       "      <td>2018-07-03 19:26:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               order_id                       customer_id  \\\n",
       "3002   2d1e2d5bf4dc7227b3bfebb81328c15f  ec05a6d8558c6455f0cbbd8a420ad34f   \n",
       "20618  f5dd62b788049ad9fc0526e3ad11a097  5e89028e024b381dc84a13a3570decb4   \n",
       "43834  2ebdfc4f15f23b91474edf87475f108e  29f0540231702fda0cfdee0a310f11aa   \n",
       "79263  e69f75a717d64fc5ecdfae42b2e8e086  cfda40ca8dd0a5d486a9635b611b398a   \n",
       "82868  0d3268bad9b086af767785e3f0fc0133  4f1d63d35fb7c8999853b2699f5c7649   \n",
       "92643  2d858f451373b04fb5c984a1cc2defaf  e08caf668d499a6d643dafd7c5cc498a   \n",
       "97647  ab7c89dc1bf4a1ead9d6ec1ec8968a84  dd1b84a7286eb4524d52af4256c0ba24   \n",
       "98038  20edc82cf5400ce95e1afacc25798b31  28c37425f1127d887d7337f284080a0f   \n",
       "\n",
       "      order_status order_purchase_timestamp   order_approved_at  \\\n",
       "3002     delivered      2017-11-28 17:44:07 2017-11-28 17:56:40   \n",
       "20618    delivered      2018-06-20 06:58:43 2018-06-20 07:19:05   \n",
       "43834    delivered      2018-07-01 17:05:11 2018-07-01 17:15:12   \n",
       "79263    delivered      2018-07-01 22:05:55 2018-07-01 22:15:14   \n",
       "82868    delivered      2018-07-01 21:14:02 2018-07-01 21:29:54   \n",
       "92643    delivered      2017-05-25 23:22:43 2017-05-25 23:30:16   \n",
       "97647    delivered      2018-06-08 12:09:39 2018-06-08 12:36:39   \n",
       "98038    delivered      2018-06-27 16:09:12 2018-06-27 16:29:30   \n",
       "\n",
       "      order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "3002           2017-11-30 18:12:23                           NaT   \n",
       "20618          2018-06-25 08:05:00                           NaT   \n",
       "43834          2018-07-03 13:57:00                           NaT   \n",
       "79263          2018-07-03 13:57:00                           NaT   \n",
       "82868          2018-07-03 09:28:00                           NaT   \n",
       "92643                          NaT                           NaT   \n",
       "97647          2018-06-12 14:10:00                           NaT   \n",
       "98038          2018-07-03 19:26:00                           NaT   \n",
       "\n",
       "      order_estimated_delivery_date  \n",
       "3002                     2017-12-18  \n",
       "20618                    2018-07-16  \n",
       "43834                    2018-07-30  \n",
       "79263                    2018-07-30  \n",
       "82868                    2018-07-24  \n",
       "92643                    2017-06-23  \n",
       "97647                    2018-06-26  \n",
       "98038                    2018-07-19  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier / missing analysis\n",
    "df[(df['order_status'] == 'delivered') & (df['order_delivered_customer_date'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730a4315",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.UnsupportedOperationException: getSubject is not supported\r\n\tat java.base/javax.security.auth.Subject.getSubject(Subject.java:277)\r\n\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:588)\r\n\tat org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2446)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2446)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:339)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\r\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)\r\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1474)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col, mean\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m spark = \u001b[43mSparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOlistOrders\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m sdf = spark.read.csv(\u001b[33m'\u001b[39m\u001b[33m../data/raw/olist_orders_dataset.csv\u001b[39m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m sdf.printSchema()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py:556\u001b[39m, in \u001b[36mSparkSession.Builder.getOrCreate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    554\u001b[39m     sparkConf.set(key, value)\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[32m    559\u001b[39m session = SparkSession(sc, options=\u001b[38;5;28mself\u001b[39m._options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\pyspark\\core\\context.py:523\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\pyspark\\core\\context.py:207\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    205\u001b[39m SparkContext._ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway=gateway, conf=conf)\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\pyspark\\core\\context.py:300\u001b[39m, in \u001b[36mSparkContext._do_init\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28mself\u001b[39m.environment[\u001b[33m\"\u001b[39m\u001b[33mPYTHONHASHSEED\u001b[39m\u001b[33m\"\u001b[39m] = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mPYTHONHASHSEED\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28mself\u001b[39m._jsc = jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28mself\u001b[39m._conf = SparkConf(_jconf=\u001b[38;5;28mself\u001b[39m._jsc.sc().conf())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\pyspark\\core\\context.py:429\u001b[39m, in \u001b[36mSparkContext._initialize_context\u001b[39m\u001b[34m(self, jconf)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1627\u001b[39m, in \u001b[36mJavaClass.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1621\u001b[39m command = proto.CONSTRUCTOR_COMMAND_NAME +\\\n\u001b[32m   1622\u001b[39m     \u001b[38;5;28mself\u001b[39m._command_header +\\\n\u001b[32m   1623\u001b[39m     args_command +\\\n\u001b[32m   1624\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1626\u001b[39m answer = \u001b[38;5;28mself\u001b[39m._gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1627\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tingweikoh.intern\\Test\\de\\.venv\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.UnsupportedOperationException: getSubject is not supported\r\n\tat java.base/javax.security.auth.Subject.getSubject(Subject.java:277)\r\n\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:588)\r\n\tat org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2446)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2446)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:339)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)\r\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)\r\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1474)\r\n"
     ]
    }
   ],
   "source": [
    "# load onto pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, mean\n",
    "spark = SparkSession.builder.appName(\"OlistOrders\").getOrCreate()\n",
    "\n",
    "\n",
    "sdf = spark.read.csv('../data/raw/olist_orders_dataset.csv', header=True, inferSchema=True)\n",
    "sdf.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
